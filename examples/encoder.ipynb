{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_varying = np.random.randn(100, 10, 450)\n",
    "static = np.random.randn(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, ks = 2, pad = 1):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.static_layer = nn.Linear(10, 50)\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(10, 25, kernel_size = ks, padding = pad, dilation = 1),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv1d(25, 25, kernel_size = ks, padding = pad, dilation  = 2),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv1d(25, 50, kernel_size = ks, padding = pad, dilation = 7),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Flatten())\n",
    "        \n",
    "    def forward(self, static, time_varying):\n",
    "        \n",
    "        static_enc = self.static_layer(static)\n",
    "        \n",
    "        time_varying_enc = self.conv_layer(time_varying)\n",
    "        \n",
    "        return torch.cat((static_enc, time_varying_enc), axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out2 = nn.Linear(hidden_size, output_size)\n",
    "        self.attention = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, encoding):\n",
    "        hidden = self.out1(encoding)\n",
    "        output = self.out2(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 385)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_varying[1][:, :385].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poorMansMQCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, num_timesteps, output_size, hidden_size, input_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(input_size, hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, static, time_varying):\n",
    "        \n",
    "        encoding = self.encoder(static, time_varying[:, :self.num_timesteps])\n",
    "        \n",
    "        output = self.decoder(encoding)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = poorMansMQCNN(e, d, num_timesteps = 365, \n",
    "                  output_size = 85, \n",
    "                  hidden_size = 500, \n",
    "                  input_size = 2700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor(static).float()\n",
    "t = torch.tensor(time_varying).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 365])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, :365].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 85])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(s, t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}