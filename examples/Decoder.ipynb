{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticLayer(nn.Module):\n",
    "    def __init__(self,in_channels, Trnn, static_features, out_channels = 30, dropout = 0.4):\n",
    "        super().__init__()\n",
    "        self.Trnn = Trnn\n",
    "        self.static_features = static_features\n",
    "        self.dropout = dropout\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.static = nn.Linear(self.in_channels, self.out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[[self.static_features]].squeeze(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.static(x)\n",
    "        return x.unsqueeze(1).repeat(1, self.Trnn, 1)\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, timevarying_features, out_channels = 30, kernel_size = 2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.timevarying_features = timevarying_features\n",
    "\n",
    "        c1 = nn.Conv1d(self.in_channels, self.out_channels, self.kernel_size, dilation = 1)\n",
    "        c2 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size, dilation = 2)\n",
    "        c3 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size, dilation = 4)\n",
    "        c4 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size, dilation = 8)\n",
    "        c5 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size, dilation = 16)\n",
    "        c6 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size, dilation = 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_t = x[[self.timevarying_features]]\n",
    "        x_t = x_t.permute(0, 2, 1)\n",
    "        x_t = F.pad(x_t, (0,0), \"constant\", 0)\n",
    "        x_t = c1(x_t)\n",
    "        x_t = F.pad(x_t, (2,0), \"constant\", 0)\n",
    "        x_t = c2(x_t)\n",
    "        x_t = F.pad(x_t, (4,0), \"constant\", 0)\n",
    "        x_t = c3(x_t)\n",
    "        x_t = F.pad(x_t, (8,0), \"constant\", 0)\n",
    "        x_t = c4(x_t)\n",
    "        x_t = F.pad(x_t, (16,0), \"constant\", 0)\n",
    "        x_t = c5(x_t)\n",
    "        x_t = F.pad(x_t, (32,0), \"constant\", 0)\n",
    "        x_t = c6(x_t)\n",
    "        \n",
    "        return x_t.permute(0, 2, 1)\n",
    "\n",
    "class ExpandLayer(nn.Module):\n",
    "    \"\"\"Expands the dimension referred to as `expand_axis` into two\n",
    "    dimensions by applying a sliding window. For example, a tensor of\n",
    "    shape (1, 4, 2) as follows:\n",
    "\n",
    "    [[[0. 1.]\n",
    "      [2. 3.]\n",
    "      [4. 5.]\n",
    "      [6. 7.]]]\n",
    "\n",
    "    where `expand_axis` = 1 and `Trnn` = 3 (number of windows) and\n",
    "    `lead_future` = 2 (window length) will become:\n",
    "\n",
    "    [[[[0. 1.]\n",
    "       [2. 3.]]\n",
    "\n",
    "      [[2. 3.]\n",
    "       [4. 5.]]\n",
    "\n",
    "      [[4. 5.]\n",
    "       [6. 7.]]]]\n",
    "\n",
    "    Used for expanding future information tensors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Trnn : int\n",
    "        Length of the time sequence (number of windows)\n",
    "    lead_future : int\n",
    "        Number of future time points (window length)\n",
    "    expand_axis : int\n",
    "        Axis to expand\"\"\"\n",
    "\n",
    "    def __init__(self, Trnn, lead_future, future_information, **kwargs):\n",
    "        super(ExpandLayer, self).__init__(**kwargs)\n",
    "    \n",
    "        self.Trnn = Trnn\n",
    "        self.future_information = future_information\n",
    "        self.lead_future = lead_future\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First create a matrix of indices, which we will use to slice\n",
    "        # `input` along `expand_axis`. For example, for Trnn=3 and\n",
    "        # lead_future=2,\n",
    "        # idx = [[0. 1.]\n",
    "        #        [1. 2.]\n",
    "        #        [2. 3.]]\n",
    "        # We achieve this by doing a broadcast add of\n",
    "        # [[0.] [1.] [2.]] and [[0. 1.]]\n",
    "        x = x[[self.future_information]]\n",
    "        idx = torch.add(torch.arange(self.Trnn).unsqueeze(axis = 1), \n",
    "                        torch.arange(self.lead_future).unsqueeze(axis = 0))\n",
    "        # Now we slice `input`, taking elements from `input` that correspond to\n",
    "        # the indices in `idx` along the `expand_axis` dimension\n",
    "        return x[:, idx, :]\n",
    "\n",
    "class GlobalFutureLayer(nn.Module):\n",
    "    def __init__(self, lead_future, future_features_count, out_channels = 30):\n",
    "        super().__init__()\n",
    "        self.lead_future = lead_future\n",
    "        self.future_features_count = future_features_count\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.l1 = nn.Linear(self.lead_feature * self_future_features_count, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.Trnn, self.lead_future * self.future_features_count)\n",
    "        \n",
    "        return self.l1(x)\n",
    "    \n",
    "class  HorizonSpecific(nn.Module):\n",
    "    def __init__(self, Tpred, Trnn, num = 20):\n",
    "        super().__init__()\n",
    "        self.Tpred = Tpred\n",
    "        self.Trnn = Trnn\n",
    "        self.num = num\n",
    "        self.l1 = nn.Linear(Tpred * num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x.view(-1, self.Trnn, self.Tpred, 20)\n",
    "\n",
    "class HorizonAgnostic(nn.module):\n",
    "    def __init__(self,in_channels, out_channels, lead_future):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.lead_future = lead_future\n",
    "        \n",
    "        self.l1 = nn.Linear(self.in_channels, self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.unsqueeze(axis = 2)\n",
    "        x = x.repeat(1,1, self.lead_future, 1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class LocalMlp(nn.Module):\n",
    "    def __init__(self, in_channels, hidden, output):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        \n",
    "        self.l1 = nn.Linear(self.in_channels, self.hidden)\n",
    "        self.l2 = nn.Linear(self.hidden, self.output)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Span1(nn.Module):\n",
    "    def __init__(self, Trnn, lead_future, num_quantiles):\n",
    "        super().__init__()\n",
    "        self.Trnn = Trnn\n",
    "        self.lead_future = lead_future\n",
    "        self.num_quantiles = num_quantiles\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.Linear(x.size(-1), self.num_quantiles)\n",
    "        x = F.relu(x.contiguous().view(-1, x.size(-2), x.size(-1)))\n",
    "        x = x.view(-1, self.Trnn, self.lead_future, self.num_quantiles)\n",
    "        x = x.view(-1, Self.Trnn, self.lead_future*self.num_quantiles)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class SpanN(nn.Module):\n",
    "    def __init__(self, Trnn, lead_future, num_quantiles, spanN_count):\n",
    "        super().__init__()\n",
    "        self.Trnn = Trnn\n",
    "        self.lead_future = lead_future\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.spanN_count = spanN_count\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 1, 3, 2)\n",
    "        x = x.contiguous().view(-1, self.Trnn, x.size(-2) * x.size(-1))\n",
    "\n",
    "        x = nn.Linear(x.size(-1), self.spanN_count * self.num_quantiles)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MQCNNModel(nn.Module):\n",
    "    def __init__(self, Trnn, static_features, timevarying_features, future_information, ltsp, lead_future):\n",
    "        super(MQCNNModel, self).__init__()\n",
    "        \n",
    "        self.Trnn = Trnn\n",
    "        self.static_features = static_features\n",
    "        self.timevarying_features = timevarying_features\n",
    "        self.future_information = future_information\n",
    "        self.ltsp = ltsp\n",
    "        self.lead_future = lead_future\n",
    "\n",
    "        encoder = MQCNNEncoder(self.Trnn, self.static_features, self.timevarying_features)\n",
    "        decoder = MQCNNDecoder(self.Trnn, self.lead_future, self.ltsp, self.future_information, self.future_information)\n",
    "\n",
    "\n",
    "class MQCNNEncoder(nn.Module):\n",
    "    def __init__(self, Trnn, static_features, timevarying_features):\n",
    "        super(MQCNNEncoder, self).__init__()\n",
    "        self.Trnn = Trnn\n",
    "        self.static_features = static_features\n",
    "        self.timevarying_features = timevarying_features\n",
    "        self.static = StaticLayer(in_channels = len(self.static_features),\n",
    "                                  Trnn = self.Trnn,\n",
    "                                  static_features = self.static_features)\n",
    "\n",
    "        self.conv = ConvLayer(in_channels = len(self.timevarying_features),\n",
    "                             timevarying_features = self.timevarying_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_s = self.static(x)\n",
    "        x_t = self.conv(x)\n",
    "\n",
    "        return torch.cat((x_s, x_t), axis = 1)\n",
    "\n",
    "\n",
    "class MQCNNDecoder(nn.Module):\n",
    "    \"\"\"Decoder implementation for MQCNN\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config\n",
    "        Configurations\n",
    "    ltsp : list of tuple of int\n",
    "        List of lead-time / span tuples to make predictions for\n",
    "    expander : HybridBlock\n",
    "        Overrides default future data expander if not None\n",
    "    hf1 : HybridBlock\n",
    "        Overrides default global future layer if not None\n",
    "    hf2 : HybridBlock\n",
    "        Overrides default local future layer if not None\n",
    "    ht1 : HybridBlock\n",
    "        Overrides horizon-specific layer if not None\n",
    "    ht2 : HybridBlock\n",
    "        Overrides horizon-agnostic layer if not None\n",
    "    h : HybridBlock\n",
    "        Overrides local MLP if not None\n",
    "    span_1 : HybridBlock\n",
    "        Overrides span 1 layer if not None\n",
    "    span_N : HybridBlock\n",
    "        Overrides span N layer if not None\n",
    "\n",
    "    Inputs:\n",
    "        - **xf** : Future data of shape\n",
    "            (batch_size, Trnn + lead_future - 1, num_future_ts_features)\n",
    "        - **encoded** : Encoded input tensor of shape\n",
    "            (batch_size, Trnn, n) for some n\n",
    "    Outputs:\n",
    "        - **pred_1** :  Span 1 predictions of shape\n",
    "            (batch_size, Trnn, Tpred * num_quantiles)\n",
    "        - **pred_N** : Span N predictions of shape\n",
    "            (batch_size, Trnn, span_N_count * num_quantiles)\n",
    "\n",
    "        In both outputs, the last dimensions has the predictions grouped\n",
    "        together by quantile. For example, the quantiles are P10 and P90\n",
    "        then the span 1 predictions will be:\n",
    "        Tpred_0_p50, Tpred_1_p50, ..., Tpred_N_p50, Tpred_0_p90,\n",
    "        Tpred_1_p90, ... Tpred_N_90\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Trnn, lead_future, future_information, ltsp, num_quantiles = 2,expander=None, hf1=None, hf2=None,\n",
    "                 ht1=None, ht2=None, h=None, span_1=None, span_N=None,\n",
    "                 **kwargs):\n",
    "        super(MQCNNDecoder, self).__init__(**kwargs)\n",
    "        self.future_features_count = len(future_information)\n",
    "        self.future_information = future_information\n",
    "        self.Trnn = Trnn\n",
    "        self.lead_future = lead_future\n",
    "        self.ltsp = ltsp\n",
    "        self.num_quantiles = num_quantiles\n",
    "\n",
    "        # We assume that Tpred == span1_count.\n",
    "        self.Tpred = max(map(lambda x: x[0] + x[1], self.ltsp))\n",
    "        span1_count = len(list(filter(lambda x: x[1] == 1, self.ltsp)))\n",
    "        #print(self.Tpred, span1_count)\n",
    "        #assert span1_count == self.Tpred, f\"Number of span 1 horizons: {span1_count}\\\n",
    "                                            #does not match Tpred: {self.Tpred}\" \n",
    "\n",
    "        self.spanN_count = len(list(filter(lambda x: x[1] != 1, self.ltsp)))\n",
    "        # Setting default components:\n",
    "        if expander is None:\n",
    "            expander = ExpandLayer(self.Trnn, self.lead_future, self.future_information)\n",
    "        if hf1 is None:\n",
    "            hf1 = GlobalFutureLayer(self.lead_future, self.future_features_count, out_channels=30)\n",
    "        if ht1 is None:\n",
    "            ht1 = HorizonSpecific(self.Tpred, self.Trnn, num = 20)\n",
    "        if ht2 is None:\n",
    "            ht2 = HorizonAgnostic(in_channels, out_channels, self.lead_future)\n",
    "        if h is None:\n",
    "            h = LocalMlp(in_channels, hidden, output)\n",
    "        if span_1 is None:\n",
    "            span_1 = Span1(self.Trnn, self.lead_future, self.num_quantiles)\n",
    "        if span_N is None:\n",
    "            span_N = SpanN(self.Trnn, self.lead_future, self.num_quantiles, self.spanN_count)\n",
    "\n",
    "        self.expander = expander\n",
    "        self.hf1 = hf1\n",
    "        self.hf2 = hf2\n",
    "        self.ht1 = ht1\n",
    "        self.ht2 = ht2\n",
    "        self.h = h\n",
    "        self.span_1 = span_1\n",
    "        self.span_N = span_N\n",
    "\n",
    "    def forward(self, F, x, encoded):\n",
    "        xf = x[[self.future_information]]\n",
    "        expanded = self.expander(xf)\n",
    "        hf1 = self.hf1(expanded)\n",
    "        hf2 = F.tanh(expanded)\n",
    "\n",
    "        ht = torch.cat(encoded, hf1, dim=-1)\n",
    "        ht1 = self.ht1(ht)\n",
    "        ht2 = self.ht2(ht)\n",
    "        h = torch.cat(ht1, ht2, hf2, dim=-1)\n",
    "        h = self.h(h)\n",
    "        return self.span_1(h), self.span_N(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1000, 456, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(25):\n",
    "    cols.append(f'col{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features = ['col0', 'col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "timevarying_features = ['col5','col6','col7','col8','col9','col10','col11','col12','col13','col14','col15','col16','col17','col18','col19', 'col20', 'col21', 'col22', 'col23', 'col24', 'col25']\n",
    "\n",
    "future_information = ['col19', 'col20', 'col21', 'col22', 'col23', 'col24', 'col25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsp = []\n",
    "for i in range(92):\n",
    "    ltsp.append((i, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(lambda x: x[0] + x[1], ltsp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x[1] == 1, ltsp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_get_global_future_layer() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-c2641487b113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMQCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m365\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_features\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstatic_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimevarying_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimevarying_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_information\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltsp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mltsp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-2492d7e709d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Trnn, static_features, timevarying_features, future_information, ltsp, lead_future)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMQCNNEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimevarying_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMQCNNDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlead_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture_information\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture_information\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-2492d7e709d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Trnn, lead_future, future_information, ltsp, num_quantiles, expander, hf1, hf2, ht1, ht2, h, span_1, span_N, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mexpander\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpandLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlead_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture_information\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_global_future_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mhf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_local_future_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _get_global_future_layer() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "m = MQCNNModel(Trnn = 365, lead_future = 91, static_features= static_features, timevarying_features = timevarying_features, future_information = future_information, ltsp = ltsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f = torch.rand(500, 456, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 456, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.add(torch.arange(365).unsqueeze(axis = 1), torch.arange(91).unsqueeze(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ...,  88,  89,  90],\n",
       "        [  1,   2,   3,  ...,  89,  90,  91],\n",
       "        [  2,   3,   4,  ...,  90,  91,  92],\n",
       "        ...,\n",
       "        [362, 363, 364,  ..., 450, 451, 452],\n",
       "        [363, 364, 365,  ..., 451, 452, 453],\n",
       "        [364, 365, 366,  ..., 452, 453, 454]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = x_f[:, idx, :] # expanded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 91, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 910])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded.view(500, 365, 910).shape # expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1 = nn.Linear(910, 30)(x_f[:, idx, :].view(-1, 365, 910))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(500, 456, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = x[:, :365, 10:40]\n",
    "x_f = x[:, :, 40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = torch.rand(500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 10]), torch.Size([500, 365, 30]), torch.Size([500, 456, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s.shape, x_t.shape, x_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Linear(10, 30)(x_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = F.pad(x_t.permute(0, 2, 1), (1, 0), \"constant\", 0)\n",
    "c1 = nn.Conv1d(30, 30, 2, dilation = 1)(c1)\n",
    "c2 = F.pad(c1, (2, 0), \"constant\", 0)\n",
    "c2 = nn.Conv1d(30, 30, 2, dilation = 2)(c2)\n",
    "c3 = F.pad(c2, (4, 0), \"constant\", 0)\n",
    "c3 = nn.Conv1d(30, 30, 2,  dilation = 4)(c3)\n",
    "c4 = F.pad(c3, (8, 0), \"constant\", 0)\n",
    "c4 = nn.Conv1d(30, 30, 2, dilation = 8)(c4)\n",
    "c5 = F.pad(c4, (16, 0), \"constant\", 0)\n",
    "c5 = nn.Conv1d(30, 30, 2, dilation = 16)(c5)\n",
    "c6 = F.pad(c5, (32, 0), \"constant\", 0)\n",
    "c6 = nn.Conv1d(30, 30, 2, dilation = 32)(c6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c6.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.unsqueeze(1).repeat(1, 365, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 30])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.cat((s, t), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 60])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = torch.cat((hf1, encoding), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 90])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 1820])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(90, 1820)(ht).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht1 = nn.Linear(90, 1820)(ht).view(-1, 365, 91, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht2 = nn.Linear(90, 100)(ht).unsqueeze(axis = 2).repeat(1, 1, 91, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2 = F.relu(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 365, 91, 10]),\n",
       " torch.Size([500, 365, 91, 20]),\n",
       " torch.Size([500, 365, 91, 100]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded.shape, ht1.shape, ht2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.cat((ht1, ht2, hf2), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class local_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(130, 50)\n",
    "        self.l2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x  = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = local_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = l(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3 = nn.Linear(10, 2)(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = F.leaky_relu(h2.contiguous().view(-1, h3.size(-2), h3.size(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 182])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1, 365, 91, 2).view(500, 365, 182).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 91, 130])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4 = h2.permute(0, 1, 3, 2).contiguous().view(-1, 365, h2.size(-2) * h2.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 40])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(h4.size(-1), 40)(h4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.DataLoader):\n",
    "    \n",
    "    def __init__(self, data, static_features, time_varying_known, time_varying_unknown, targets):\n",
    "        \n",
    "        self.targets = targets\n",
    "        self.data = data\n",
    "        self.static = static_features\n",
    "        self.tv_known = time_varying_known\n",
    "        self.tv_unknown = time_varying_unknown\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.features['time_idx'].unique())\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        print(self.features)\n",
    "        \n",
    "        X_static = self.data.loc[self.features['time_idx'] == index, [self.static]]\n",
    "        X_tv_known = self.data.loc[self.features['time_idx'] == index, [self.tv_known]]\n",
    "        X_tv_unknown = self.data.loc[self.features['time_idx'] == index, [self.tv_unknown]]\n",
    "        Y = self.targets.loc[self.targets['time_idx'] == index]\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-85-97816950560f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-97816950560f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    static = [:10]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(500, 456, 50)\n",
    "y = x[:, :, 50]\n",
    "static = x[:, 0, :10]\n",
    "tv_known = x[:, 10:20]\n",
    "tv_unknown = [20:50]\n",
    "d = Dataset(x, static, tv_known, tv_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 10])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(500, 1, 10).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
